---
title: "introduction"
output: html_fragment
---

#### What is a Neural Network?

$\require{mhchem}$A neural network uses a supervised machine learning algorithm to discover an underlying structure in a set of data. The figure on the upper right is a simple neural network that accepts two inputs and returns a single output. A hidden layer with three nodes connects the input nodes to the output node. Weights connect each node in the hidden layer to all nodes in the input and output layers. A neural network is trained by presenting it with samples that have known inputs and outputs---that these are known is why this is a supervised method---and adjusting the weights until the difference between the known and predicted outputs is sufficiently small. Once trained, the network is used to predict the outcome of new experiments. 

#### What Does it Mean to Feed-Forward and to Backpropogate?

As suggested in the figure, training a a neural network occurs in two ways: first by feeding-forward and then by backpropogating. Feed-forward means information flows from inputs to outputs. The difference between the output and its expected value is an error. To improve the neural network's capabilities, this error is used to adjust the weights, working in the reverse direction, a process called backpropogation.

#### How Do We Model a Neuron?

A neural network uses a simple model of a neuron in which dendrites carry signals to a cell body that processes and passes the signals to an axon. The figure on the lower right shows an artificial neuron. In this model the neuron's cell body is a node, the dendrites are the node's inputs, and the axon is the node's output. The summation symbol, $\Sigma$, indicates that the inputs and their weights are combined mathematically. The S-shaped symbol represents an activation function that is applied before the node's value is sent to the next layer.

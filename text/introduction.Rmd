---
title: "introduction"
output: html_fragment
---

#### What is a Neural Network?

$\require{mhchem}$The figure on the upper right is a schematic of a small neural network that accepts two inputs, perhaps pH and temperature, and returns a single output, perhaps %yield. In between the inputs and the output are two bias terms and a hidden layer with two nodes. Weights---shown as arrows---connect nodes in the hidden layer to the nodes in the input and output layers (including the bias terms). A neural network is trained by presenting it with samples that have known inputs and outputs and adjusting the weights until the difference between the known and predicted outputs is sufficiently small. Once trained, the network is used to predict the outcome of new samples that it hasn't yet seen. 

#### What Does it Mean to Feed--Forward and to Backpropagate?

Training a neural network occurs in two ways: feeding--forward inputs and backpropagating errors. Feeding--forward means information flows from inputs to outputs. The difference between the output and its expected value is an error. To improve the neural network's capabilities, this error is used to adjust all of the network's weights, working in the reverse direction, a process called backpropagation.

#### How Do We Model a Neuron?

A neural network is a simple mathematical model of a physiological neuron in which dendrites carry signals to a cell body that processes and passes the signals to an axon. The figure on the lower right is a schematic of an artificial neuron: the neuron's cell body is a node, the dendrites are the node's inputs, and the axon is the node's output. The summation symbol, $\Sigma$, indicates that the inputs and their weights are combined mathematically. The S-shaped symbol represents an activation function that is applied before the node's value is sent to the next layer.

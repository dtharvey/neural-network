---
title: "activity2"
output: html_fragment
---
A training sample provides a set of inputs and the corresponding expected, or target, result. The difference between the target, $t$, and the output of the feed forward process, $O_1$, is an error, $E$. The goal of backpropogation is to use that error to adjust all of the neural network's weights in a way that minimizes the difference between $t$ and $O_1$.

**Exercise 1**. There are several ways to report error, but the one used here is $E = \frac{1}{2}(t - O_1)^2$. Given inputs of $I_1 = 0.600$ and $I_2 = 0.400$, a target of $t = 0.200$, and the results accessible using the after feed-forward radio button, what is the value of $E$.

**Exercise 2**. In backpropogation, the error at the output layer is spread across the weights between the layers of nodes. Beginning with the output, the algorithm adjusts the weights between the output layer and the hidden layer, and then adjusts the weights between the hidden layer and the input layer. The result is the network on the right accessible using the after backpropogation radio button. Which set of weights---those between the output layer and the hidden layer or those between the hidden layer and the input layer---show the greatest change in value? Explain why this makes sense. In which direction---more negative/less positive or more positive/less negative---are the changes in the value of these weights? Explain why this makes sense.

**Exercise 3**. Use the radio button to examine the after backpropogation neural network. The inputs,$I_1$ and $I_2$, the values of the hidden layer, $H_1$, $H_2$, and $H_3$, and the output, $O_1$ are missing because each is reset before taking a new training sample through the feed-forward process. Suppose you run the same training sample through the feed-forward network a second time, using $I_1 = 0.600$, $I_2 = 0.400$, and $t = 0.200$. Using the weights from the after backpropogation network, determine the value for $O_1$ and the resulting error. Do your results make sense?



